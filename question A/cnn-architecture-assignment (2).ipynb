{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport math\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport wandb as wb\nimport gc\nfrom tqdm import tqdm\nimport time","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-06T20:30:56.691006Z","iopub.execute_input":"2024-04-06T20:30:56.691637Z","iopub.status.idle":"2024-04-06T20:31:09.965412Z","shell.execute_reply.started":"2024-04-06T20:30:56.691607Z","shell.execute_reply":"2024-04-06T20:31:09.964445Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# api = 7ef702aa33359df589bdaccee0566a96d8c08d31","metadata":{"execution":{"iopub.status.busy":"2024-04-06T19:03:11.687960Z","iopub.execute_input":"2024-04-06T19:03:11.688321Z","iopub.status.idle":"2024-04-06T19:03:11.692445Z","shell.execute_reply.started":"2024-04-06T19:03:11.688293Z","shell.execute_reply":"2024-04-06T19:03:11.691490Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:28:51.674975Z","iopub.execute_input":"2024-04-06T20:28:51.675299Z","iopub.status.idle":"2024-04-06T20:29:10.959786Z","shell.execute_reply.started":"2024-04-06T20:28:51.675273Z","shell.execute_reply":"2024-04-06T20:29:10.958640Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-04-06 20:28:52--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.207, 172.253.119.207, 108.177.121.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3816687935 (3.6G) [application/zip]\nSaving to: 'nature_12K.zip'\n\nnature_12K.zip      100%[===================>]   3.55G   195MB/s    in 18s     \n\n2024-04-06 20:29:10 (201 MB/s) - 'nature_12K.zip' saved [3816687935/3816687935]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip -q nature_12K.zip","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:30:21.068793Z","iopub.execute_input":"2024-04-06T20:30:21.069657Z","iopub.status.idle":"2024-04-06T20:30:48.114049Z","shell.execute_reply.started":"2024-04-06T20:30:21.069622Z","shell.execute_reply":"2024-04-06T20:30:48.112980Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !rm -r inaturalist_12K","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:30:03.997633Z","iopub.execute_input":"2024-04-06T20:30:03.998560Z","iopub.status.idle":"2024-04-06T20:30:05.230906Z","shell.execute_reply.started":"2024-04-06T20:30:03.998525Z","shell.execute_reply":"2024-04-06T20:30:05.229751Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CNNArchitecture(nn.Module):\n    def __init__(self,param,h,w):\n        super(CNNArchitecture,self).__init__()\n        \n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(3, param.filters[0], param.filterSize)\n        if param.batchNormalization==True:\n            self.batchnorm1 = nn.BatchNorm2d(param.filters[0])\n        self.conv2 = nn.Conv2d(param.filters[0],param.filters[1],param.filterSize)\n        if param.batchNormalization==True:\n            self.batchnorm2 = nn.BatchNorm2d(param.filters[1])\n        self.conv3 = nn.Conv2d(param.filters[1],param.filters[2],param.filterSize)\n        if param.batchNormalization==True:\n            self.batchnorm3 = nn.BatchNorm2d(param.filters[2])\n        self.conv4 = nn.Conv2d(param.filters[2],param.filters[3],param.filterSize)\n        if param.batchNormalization==True:\n            self.batchnorm4 = nn.BatchNorm2d(param.filters[3])\n        self.conv5 = nn.Conv2d(param.filters[3],param.filters[4],param.filterSize)\n        if param.batchNormalization==True:\n            self.batchnorm5 = nn.BatchNorm2d(param.filters[4])\n        \n        self.flatten_features =None\n        #we need flatten features as an input for first dense layers without this our model will not be compatible\n        # we are sending dummy image to our cnn layers and calculating what will be the parameters of it\n        self.calculateFeatures(param,torch.rand(1,3,h,w))\n        self.linearLayers = nn.ModuleList()\n\n        #TODO: I didn't added activation layers here I have to do this work in forward pass\n        if param.denseLayers!=0:\n            self.linearLayers.append(nn.Linear(self.flatten_features,param.denseLayersSize))\n            for _ in range(param.denseLayers-1):\n                if int(param.dropout)!=0:\n                    self.linearLayers.append(nn.Dropout(param.dropout))\n                self.linearLayers.append(nn.Linear(param.denseLayersSize,param.denseLayersSize))\n                \n            self.linearLayers.append(nn.Linear(param.denseLayersSize,10))\n        else:\n            self.linearLayers.append(nn.Linear(param.flatten_features,10))\n\n    def calculateFeatures(self,param,x):\n        z = param.poolingSize\n        activation = param.activation\n        print(z)\n        x = F.max_pool2d(activation(self.conv1(x)), z)\n        print(x.size())\n        x = F.max_pool2d(activation(self.conv2(x)), z)\n        print(x.size())\n        x = F.max_pool2d(activation(self.conv3(x)),z)\n        print(x.size())\n        x = F.max_pool2d(activation(self.conv4(x)),z)\n        print(x.size())\n        x = F.max_pool2d(activation(self.conv5(x)),z)\n        print(x.size())\n        self.flatten_features = x.size(1) * x.size(2) * x.size(3)\n        \n        \n        \n    def forward(self,param, x):\n        z = param.poolingSize\n        activation = param.activation\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(activation(self.conv1(x)), z)\n        if param.batchNormalization==True:\n            x = self.batchnorm1(x)\n        # If the size is a square, you can specify with a single number\n        x = F.max_pool2d(activation(self.conv2(x)), z)\n        if param.batchNormalization == True:\n            x = self.batchnorm2(x)\n        x = F.max_pool2d(activation(self.conv3(x)),z)\n        if param.batchNormalization == True:\n            x = self.batchnorm3(x)\n        x = F.max_pool2d(activation(self.conv4(x)),z)\n        if param.batchNormalization == True:\n            x = self.batchnorm4(x)\n        x = F.max_pool2d(activation(self.conv5(x)),z)\n        if param.batchNormalization == True:\n            x = self.batchnorm5(x)\n        \n        \n        \n        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension \n        for i in range(len(self.linearLayers)-1):\n            x = activation(self.linearLayers[i](x))\n        x = self.linearLayers[-1](x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:31:12.697292Z","iopub.execute_input":"2024-04-06T20:31:12.697741Z","iopub.status.idle":"2024-04-06T20:31:12.719544Z","shell.execute_reply.started":"2024-04-06T20:31:12.697710Z","shell.execute_reply":"2024-04-06T20:31:12.718608Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Parameters:\n    def __init__(self,filters,filter_size,pooling_size,stride,multiplier,dense_layers,dense_layer_size,aug,normalization,dropout,activation,optimizers,lr):\n        self.cnnLayers = 5\n        self.filterMultiplier = multiplier# number float\n        self.filters = self.settingFilters(filters,multiplier,self.cnnLayers)\n        self.filterSize = filter_size\n        self.poolingSize = pooling_size\n        self.stride = stride\n        self.denseLayers = dense_layers\n        self.denseLayersSize = dense_layer_size\n        self.dataAugmentation = aug\n        self.batchNormalization = normalization# true or false\n        self.dropout = dropout # probabilty\n        self.activation_dict = { 'relu':F.relu,'selu':F.selu,'gelu':F.gelu,'mish':F.mish}\n        self.optimzers_dict = {'sgd':optim.SGD,'nadam':optim.NAdam,\"adam\":optim.Adam,\"rmsprop\":optim.RMSprop}\n        self.activation = self.activation_dict[activation]\n        self.optimizer = self.optimzers_dict[optimizers]\n        self.learning_rate = lr\n        \n    def settingFilters(self,filters,multiplier,layers):\n        return [filters*(multiplier**i) for i in range(layers)]","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:31:13.891314Z","iopub.execute_input":"2024-04-06T20:31:13.891694Z","iopub.status.idle":"2024-04-06T20:31:13.900338Z","shell.execute_reply.started":"2024-04-06T20:31:13.891665Z","shell.execute_reply":"2024-04-06T20:31:13.899447Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\" Set Device to GPU or CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \n\ndef to_device(data, device):\n    \"Move data to the device\"\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device,non_blocking = True)\n\nclass DeviceDataLoader():\n    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n    \n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    \n    def __iter__(self):\n        \"\"\" Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b,self.device)\n            \n    def __len__(self):\n        \"\"\" Number of batches \"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:31:14.721214Z","iopub.execute_input":"2024-04-06T20:31:14.721560Z","iopub.status.idle":"2024-04-06T20:31:14.729427Z","shell.execute_reply.started":"2024-04-06T20:31:14.721533Z","shell.execute_reply":"2024-04-06T20:31:14.728520Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_dir = 'inaturalist_12K/train'\ntest_data_dir = 'inaturalist_12K/val'\ndataset = ImageFolder(data_dir,transform = transforms.Compose([\n    transforms.Resize((512,512)),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n]))\nval_dataset = ImageFolder(test_data_dir,transforms.Compose([\n    transforms.Resize((512,512)),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n]))\nbatch_size = 64\ntrain_dl = DataLoader(dataset, batch_size, shuffle = True,pin_memory=True, num_workers = 2)\nval_dl = DataLoader(val_dataset, batch_size,shuffle = True,pin_memory = True, num_workers = 2)\ndevice = get_default_device()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:31:21.069863Z","iopub.execute_input":"2024-04-06T20:31:21.070210Z","iopub.status.idle":"2024-04-06T20:31:21.180732Z","shell.execute_reply.started":"2024-04-06T20:31:21.070182Z","shell.execute_reply":"2024-04-06T20:31:21.179765Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dl_gpu = DeviceDataLoader(train_dl,device)\nval_dl_gpu = DeviceDataLoader(val_dl,device)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:58:50.506796Z","iopub.execute_input":"2024-04-06T18:58:50.507160Z","iopub.status.idle":"2024-04-06T18:58:50.511921Z","shell.execute_reply.started":"2024-04-06T18:58:50.507130Z","shell.execute_reply":"2024-04-06T18:58:50.510796Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"img,labels = next(iter(train_dl))\nheight = img[0].size(1)\nwidth = img[0].size(2)\nprint(height,width)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:58:51.073591Z","iopub.execute_input":"2024-04-06T18:58:51.074407Z","iopub.status.idle":"2024-04-06T18:58:54.147211Z","shell.execute_reply.started":"2024-04-06T18:58:51.074367Z","shell.execute_reply":"2024-04-06T18:58:54.146159Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"512 512\n","output_type":"stream"}]},{"cell_type":"code","source":"# filters = 48 # filters are here represent number of filters in cnn \n# filter_size = 5\n# pooling_size = 2\n# stride=2\n# multiplier = 2\n# dense_layers = 5\n# dense_size = 256\n# aug = False\n# normalization = True\n# dropout = 0.25\n# activation = 'relu'\n# optimizers = 'adam'\n# ob = Parameters(filters,filter_size,pooling_size,stride,multiplier,dense_layers,dense_size,aug,normalization,dropout,activation,optimizers)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:37:15.297500Z","iopub.execute_input":"2024-04-06T17:37:15.297826Z","iopub.status.idle":"2024-04-06T17:37:15.302707Z","shell.execute_reply.started":"2024-04-06T17:37:15.297794Z","shell.execute_reply":"2024-04-06T17:37:15.301674Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:58:57.133333Z","iopub.execute_input":"2024-04-06T18:58:57.133676Z","iopub.status.idle":"2024-04-06T18:58:57.138783Z","shell.execute_reply.started":"2024-04-06T18:58:57.133643Z","shell.execute_reply":"2024-04-06T18:58:57.137949Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, ob ,dataset_tensor, datatype ,use_cuda = True):\n    model.eval()\n    correct = 0\n    total = 0\n    total_loss  = []\n    criterion = nn.CrossEntropyLoss()\n    \n    with torch.no_grad():\n        for data in dataset_tensor:\n            images, labels = data\n           # print(images.device)\n            outputs = model.forward(ob,images)\n#             loss+=F.cross_entropy(outputs,labels)\n            loss= criterion(outputs,labels)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            total_loss.append(loss)\n    loss = torch.stack(total_loss).mean().item()\n    acc = (100*correct/total)\n    print(f'{datatype}_accuracy: {acc}, {datatype}_loss: {loss}')\n    wb.log({f'{datatype}_accuracy': acc})\n    wb.log({f'{datatype}_loss': loss})\n\n    \n# this function will also work without gpu\ndef fit(ob,model,train_gpu,val_gpu,epochs):\n    optimizer = ob.optimizer(model.parameters(),lr = ob.learning_rate)\n    history =[]\n    for i in range(epochs):\n        model.train()\n#         training_loss = []\n        acc =[]\n        for ind, (images, labels) in enumerate(tqdm(train_gpu, desc=f'Training Progress {i+1}')):\n            optimizer.zero_grad()\n            pred = model.forward(ob,images)\n        \n            loss = F.cross_entropy(pred, labels)\n#             training_loss.append(loss)\n            loss.backward()\n            optimizer.step()\n        training_acc = evaluate(model,ob,train_gpu,'training')\n        validation_acc = evaluate(model,ob,val_gpu,'validation')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:59:00.038248Z","iopub.execute_input":"2024-04-06T18:59:00.038598Z","iopub.status.idle":"2024-04-06T18:59:00.050332Z","shell.execute_reply.started":"2024-04-06T18:59:00.038572Z","shell.execute_reply":"2024-04-06T18:59:00.049390Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"epochs =10","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:59:02.041737Z","iopub.execute_input":"2024-04-06T18:59:02.042586Z","iopub.status.idle":"2024-04-06T18:59:02.046408Z","shell.execute_reply.started":"2024-04-06T18:59:02.042550Z","shell.execute_reply":"2024-04-06T18:59:02.045441Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def main():\n    wb.init(project=\"Assignment 2 cnn\")\n    config = wb.config\n    run_name = f'{config.optimizer}_{config.activation}_{config.filters}_{config.normalization}_{config.multiplier}_{config.filter_size}'\n\n    # Set the run name\n    wb.run.name = run_name\n    wb.run.save()\n   # epochs = config.epochs\n    aug = False\n    # Define and train the model as before\n    ob = Parameters(config.filters,config.filter_size,config.pooling_size,config.stride,config.multiplier,config.dense_layer,config.dense_size,aug,config.normalization,config.dropout,config.activation,config.optimizer,config.learning_rate)\n    model = CNNArchitecture(ob,height,width)\n#     if torch.cuda.is_available():\n#     gpu_model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n    if torch.cuda.is_available():\n        model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n        optimizer = ob.optimizer(model.parameters(),lr = ob.learning_rate)\n        history =[]\n        for i in range(epochs):\n            model.train()\n#         training_loss = []\n\n            for ind, (images, labels) in enumerate(tqdm(train_dl_gpu, desc=f'Training Progress {i+1}')):\n                optimizer.zero_grad()\n                pred = model.forward(ob,images)\n        \n                loss = F.cross_entropy(pred, labels)\n#             training_loss.append(loss)\n                loss.backward()\n                optimizer.step()\n            training_acc = evaluate(model,ob,train_dl_gpu,'training')\n            validation_acc = evaluate(model,ob,val_dl_gpu,'validation')\n        #fit(ob,model,train_dl_gpu,val_dl_gpu,10)\n        model.cpu()\n        del model\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:59:11.390516Z","iopub.execute_input":"2024-04-06T18:59:11.391199Z","iopub.status.idle":"2024-04-06T18:59:11.401445Z","shell.execute_reply.started":"2024-04-06T18:59:11.391160Z","shell.execute_reply":"2024-04-06T18:59:11.400451Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#filters,filter_size,pooling_size,stride,multiplier,learning_rate,dense_layers,dense_size,aug,normalization,dropout,activation,optimizers\nsweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep cross entropy',\n    'metric': {\n      'name': 'validation_accuracy',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'filters': {\n          'values': [32,128,64,16]\n        },\n        'filter_size': {\n          'values': [3,5]\n        },\n        'multiplier':{\n            'values':[1,2]\n        },\n        'pooling_size':{\n            'values':[2]\n        },\n        'stride':{\n            'values':[1,2]\n        },\n        'learning_rate': {\n            'values':[1e-3,1e-4]\n        },\n        'dense_layer':{\n            'values': [1,2,3]\n        },\n        'dense_size':{\n            'values':[128,256,512]\n        },\n        \n        'normalization':{\n            'values': [True,False]\n        },\n        'dropout': {\n            'values': [0, 0.2, 0.4]\n        },\n        'activation': {\n            'values': ['relu', 'selu','mish','gelu']\n        },\n        'optimizer': {\n            'values': ['nadam', 'adam','sgd','rmsprop']\n        }\n    }\n}\n\n\nsweep_id = wb.sweep(sweep=sweep_config,project='Assignment 2 cnn')\nwb.agent(\"3q087yux\"  , function = main , count = 1)\nwb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:59:55.471931Z","iopub.execute_input":"2024-04-06T18:59:55.472566Z","iopub.status.idle":"2024-04-06T19:01:06.222317Z","shell.execute_reply.started":"2024-04-06T18:59:55.472530Z","shell.execute_reply":"2024-04-06T19:01:06.221484Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: 04ajajzq\nSweep URL: https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/sweeps/04ajajzq\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: okr276qn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_layer: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmultiplier: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tstride: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m023\u001b[0m (\u001b[33mdeeplearning-assignment\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240406_190002-okr276qn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/runs/okr276qn' target=\"_blank\">lemon-sweep-49</a></strong> to <a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/sweeps/3q087yux' target=\"_blank\">https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/sweeps/3q087yux</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn' target=\"_blank\">https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/sweeps/3q087yux' target=\"_blank\">https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/sweeps/3q087yux</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/runs/okr276qn' target=\"_blank\">https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/runs/okr276qn</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n","output_type":"stream"},{"name":"stdout","text":"2\ntorch.Size([1, 128, 255, 255])\ntorch.Size([1, 256, 126, 126])\ntorch.Size([1, 512, 62, 62])\ntorch.Size([1, 1024, 30, 30])\ntorch.Size([1, 2048, 14, 14])\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 1:   0%|          | 0/157 [00:06<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lemon-sweep-49</strong> at: <a href='https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/runs/okr276qn' target=\"_blank\">https://wandb.ai/deeplearning-assignment/Assignment%202%20cnn/runs/okr276qn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240406_190002-okr276qn/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run okr276qn errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/181686893.py\", line 26, in main\n    pred = model.forward(ob,images)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 110, in parallel_apply\n    output.reraise()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 694, in reraise\n    raise exception\nRuntimeError: Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/1438758025.py\", line 84, in forward\n    x = activation(self.linearLayers[i](x))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run okr276qn errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/181686893.py\", line 26, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     pred = model.forward(ob,images)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 110, in parallel_apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output.reraise()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 694, in reraise\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exception\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Caught RuntimeError in replica 1 on device 1.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Original Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = module(*input, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1438758025.py\", line 84, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = activation(self.linearLayers[i](x))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.linear(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","output_type":"stream"}]},{"cell_type":"code","source":"fit(ob,gpu_model,train_dl,val_dl,50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"doing garbage collection ","metadata":{}},{"cell_type":"code","source":"\n\nfrom numba import cuda\ndevice = cuda.get_current_device()\ndevice.reset()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T17:22:58.741196Z","iopub.execute_input":"2024-04-06T17:22:58.741875Z","iopub.status.idle":"2024-04-06T17:23:00.273404Z","shell.execute_reply.started":"2024-04-06T17:22:58.741841Z","shell.execute_reply":"2024-04-06T17:23:00.272579Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:10:47.678543Z","iopub.status.busy":"2024-03-29T19:10:47.677711Z","iopub.status.idle":"2024-03-29T19:10:47.910581Z","shell.execute_reply":"2024-03-29T19:10:47.909730Z","shell.execute_reply.started":"2024-03-29T19:10:47.678501Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}